{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: TensorFlow and Edge Detection using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from __future__ import division\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import shutil\n",
    "from utils import *\n",
    "from HOG import *\n",
    "from svm_tf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eval_neg', 'train_neg', 'test_pos', 'eval_pos', 'train_pos', 'test_neg']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = np.load('pedestrian_dataset.npz')    # extracted from the original Dalal and Triggs paper dataset available here: http://pascal.inrialpes.fr/data/human/\n",
    "[k for k in datasets.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20433dd36ca48b59452f67b151718bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=249, description='k', max=499), IntSlider(value=0, description='p', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### EXPLORE THE DATASET!\n",
    "# p=0 are negative examples\n",
    "# p=1 are positive examples\n",
    "@interact(k = (0, datasets[\"train_neg\"].shape[0] - 1), p = (0, 1))\n",
    "def view_img(k, p):\n",
    "    d = {0: \"train_neg\", 1: \"train_pos\"}\n",
    "    plt.imshow(datasets[d[p]][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bbada81647454eaba681955b121e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=249, description='k', max=499), IntSlider(value=0, description='p', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### VISUALIZE HOGs!\n",
    "# p=0 are negative examples\n",
    "# p=1 are positive examples\n",
    "@interact(k = (0, datasets[\"train_neg\"].shape[0]-1), p = (0, 1))\n",
    "def view_img(k, p):\n",
    "    d = {0: \"train_neg\", 1: \"train_pos\"}\n",
    "    plt.figure(figsize = (15,15))    # feel free to change this depending on your screen resolution\n",
    "    plt.imshow(datasets[d[p]][k])\n",
    "    plot_cell_hogs(tf_histogram_of_oriented_gradients(datasets[d[p]][k])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do this after you have trained your SVM with HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on hog_model/trained_weights: Not found: hog_model; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1a12da682a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msvm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_pos\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_neg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aa274b/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    181\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aa274b/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aa274b/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_api_names_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train.NewCheckpointReader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aa274b/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_CheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on hog_model/trained_weights: Not found: hog_model; No such file or directory"
     ]
    }
   ],
   "source": [
    "### VISUALIZE WEIGHTED HOGs!\n",
    "##################################\n",
    "(x_train, y_train), (x_eval, y_eval), (x_pred, y_true) = get_hog_data()\n",
    "data = {}\n",
    "data['x_train'] = x_train\n",
    "data['y_train'] = y_train\n",
    "data['x_eval'] = x_eval\n",
    "data['y_eval'] = y_eval\n",
    "data['x_pred'] = x_pred\n",
    "data['y_true']  = y_true\n",
    "data['name'] = 'hog'\n",
    "\n",
    "model_dir = \"hog_model/trained_weights\"\n",
    "\n",
    "dim = data['x_train'].shape[-1]\n",
    "svm_model = SVM(dim=dim)\n",
    "svm_model.load_weights(model_dir)\n",
    "\n",
    "data = np.concatenate([datasets[\"test_pos\"], datasets[\"test_neg\"]], axis=0)\n",
    "\n",
    "weights = np.reshape(svm_model.W.numpy(), [1, -1])\n",
    "pos_weights = np.maximum(weights, 0)\n",
    "neg_weights = -np.minimum(weights, 0)\n",
    "file_exists = False\n",
    "try:\n",
    "    misclass_idx = np.load(\"hog_misclass_idx.npy\")\n",
    "    file_exists = True\n",
    "except OSError:\n",
    "    print(\"\\n\\nYou need to run the svm with HOG features first! hog_misclass_idx.py doesn't exist yet.\\n\\n\")\n",
    "\n",
    "if file_exists:\n",
    "    @interact(k = (0, data.shape[0]-1), show_image = (False, True))\n",
    "    def view_img(k, show_image):\n",
    "\n",
    "        misclass_idx = np.load(\"hog_misclass_idx.npy\")\n",
    "        plt.figure(figsize = (15,15))    # feel free to change this depending on your screen resolution\n",
    "        plt.imshow(data[k])\n",
    "        hog = hog_descriptor(data[k]).numpy()\n",
    "        unweighted_block_hogs = np.mean(hog.reshape([16, 8, 1, 9]), axis=2)\n",
    "        pos_weighted_block_hogs = np.mean(pos_weights.reshape([16, 8, 1, 9])*hog.reshape([16, 8, 1, 9]), axis=2)\n",
    "        neg_weighted_block_hogs = np.mean(neg_weights.reshape([16, 8, 1, 9])*hog.reshape([16, 8, 1, 9]), axis=2)\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        color = 'yellow' if show_image else 'white'\n",
    "        plt.imshow(show_image*data[k])\n",
    "        plot_cell_hogs(unweighted_block_hogs, pixels_in_cell=8, color=color)\n",
    "        if k in misclass_idx:\n",
    "            plt.title(\"Misclassified!\")\n",
    "        else:\n",
    "            plt.title(\"Classified correctly\")\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(show_image*data[k])\n",
    "        plot_cell_hogs(pos_weighted_block_hogs, pixels_in_cell=8, color=color)\n",
    "        plt.title(\"Positive Weights\")\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(show_image*data[k])\n",
    "        plot_cell_hogs(neg_weighted_block_hogs, pixels_in_cell=8, color=color)\n",
    "        plt.title(\"Negative Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
